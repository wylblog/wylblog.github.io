<!DOCTYPE HTML><html lang="zh-CN"><style type="text/css" lang="css">#loading-container{position:fixed;top:0;left:0;min-height:100vh;width:100vw;z-index:9999;display:flex;flex-direction:column;justify-content:center;align-items:center;background:#fff;text-align:center;-webkit-transition:opacity 1s ease;-moz-transition:opacity 1s ease;-o-transition:opacity 1s ease;transition:opacity 1s ease}.loading-image{width:120px;height:50px;transform:translate(-50%)}.loading-image div:nth-child(2){-webkit-animation:pacman-balls 1s linear 0s infinite;animation:pacman-balls 1s linear 0s infinite}.loading-image div:nth-child(3){-webkit-animation:pacman-balls 1s linear .33s infinite;animation:pacman-balls 1s linear .33s infinite}.loading-image div:nth-child(4){-webkit-animation:pacman-balls 1s linear .66s infinite;animation:pacman-balls 1s linear .66s infinite}.loading-image div:nth-child(5){-webkit-animation:pacman-balls 1s linear .99s infinite;animation:pacman-balls 1s linear .99s infinite}.loading-image div:first-of-type{width:0;height:0;border:25px solid #49b1f5;border-right-color:transparent;border-radius:25px;-webkit-animation:rotate_pacman_half_up .5s 0s infinite;animation:rotate_pacman_half_up .5s 0s infinite}.loading-image div:nth-child(2){width:0;height:0;border:25px solid #49b1f5;border-right-color:transparent;border-radius:25px;-webkit-animation:rotate_pacman_half_down .5s 0s infinite;animation:rotate_pacman_half_down .5s 0s infinite;margin-top:-50px}@-webkit-keyframes rotate_pacman_half_up{0%{transform:rotate(270deg)}50%{transform:rotate(1turn)}to{transform:rotate(270deg)}}@keyframes rotate_pacman_half_up{0%{transform:rotate(270deg)}50%{transform:rotate(1turn)}to{transform:rotate(270deg)}}@-webkit-keyframes rotate_pacman_half_down{0%{transform:rotate(90deg)}50%{transform:rotate(0)}to{transform:rotate(90deg)}}@keyframes rotate_pacman_half_down{0%{transform:rotate(90deg)}50%{transform:rotate(0)}to{transform:rotate(90deg)}}@-webkit-keyframes pacman-balls{75%{opacity:.7}to{transform:translate(-100px,-6.25px)}}@keyframes pacman-balls{75%{opacity:.7}to{transform:translate(-100px,-6.25px)}}.loading-image div:nth-child(3),.loading-image div:nth-child(4),.loading-image div:nth-child(5),.loading-image div:nth-child(6){background-color:#49b1f5;width:15px;height:15px;border-radius:100%;margin:2px;width:10px;height:10px;position:absolute;transform:translateY(-6.25px);top:25px;left:100px}.loading-text{margin-bottom:20vh;text-align:center;color:#2c3e50;font-size:2rem;box-sizing:border-box;padding:0 10px;text-shadow:0 2px 10px rgba(0,0,0,.2)}@media only screen and (max-width:500px){.loading-text{font-size:1.5rem}}.fadeout{opacity:0}@-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}@keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0)}}</style><script>setTimeout(function(){let e=document.getElementById("loading-container");e.className="fadeout",setTimeout(function(){e.style.display="none"},1500)},800)</script><head><meta charset="utf-8"><meta name="keywords" content="Flume配置(1.9.0)和基本使用, WuYiling&#39; Blog"><meta name="description" content="Flume安装配置1. 概述1.1 flume定义Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume基于流式架构，灵活简单。

1.2 Flume组成架构
架构图:



架构详解:"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer-when-downgrade"><title>Flume配置(1.9.0)和基本使用 | WuYiling&#39; Blog</title><link rel="icon" type="image/png" href="/medias/wylblog/avatar_wyl.webp"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><link rel="stylesheet" href="/css/post.css"><link rel="stylesheet" type="text/css" href="/css/reward.css"><script src="/libs/jquery/jquery-3.6.0.min.js"></script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="loading-container"><p class="loading-text">嘘~ 正在从服务器偷取页面 . . . 可尝试再次刷新 . . .</p><div class="loading-image"><div></div><div></div><div></div><div></div><div></div></div></div><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/wylblog/avatar_wyl.webp" class="logo-img" alt="LOGO"> <span class="logo-span">WuYiling&#39; Blog</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友链</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/wylblog/avatar_wyl.webp" class="logo-img circle responsive-img"><div class="logo-name">WuYiling&#39; Blog</div><div class="logo-desc">本网站是个人兴趣爱好，总结分享经验，记录生活点滴的平台，希望在以后的学习旅途中，走出自己的风景。</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友链</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li></ul></div></div></nav></header><script src="/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/12.webp)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Flume配置(1.9.0)和基本使用</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/Bigdata/"><span class="chip bg-color">Bigdata</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BF%90%E7%BB%B4%E7%B3%BB%E5%88%97/" class="post-category">大数据运维系列</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2024-11-27</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2024-11-27</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 6.5k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 31 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><link rel="stylesheet" href="/libs/prism/prism.min.css"><div class="card-content article-card-content"><div id="articleContent"><h1 id="Flume安装配置"><a href="#Flume安装配置" class="headerlink" title="Flume安装配置"></a>Flume安装配置</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><h3 id="1-1-flume定义"><a href="#1-1-flume定义" class="headerlink" title="1.1 flume定义"></a>1.1 flume定义</h3><p>Flume是Cloudera提供的一个高可用的，高可靠的，<code>分布式的海量日志采集、聚合和传输的系统</code>。Flume基于流式架构，灵活简单。</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141446932.png" alt="image-20240114144609871"></p><h3 id="1-2-Flume组成架构"><a href="#1-2-Flume组成架构" class="headerlink" title="1.2 Flume组成架构"></a>1.2 Flume组成架构</h3><blockquote><p>架构图:</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141446973.png" alt="image-20240114144657928"></p><blockquote><p>架构详解:</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141447104.png" alt="image-20240114144734040"></p><blockquote><p>组件介绍:</p></blockquote><p>:one:Agent</p><p>​	Agent是一个JVM进程，它以事件的形式将数据从源头送至目的，<code>是Flume数据传输的基本单元</code>。</p><p>​	Agent主要有3个部分组成，Source、Channel、Sink。</p><p>:two:Source</p><p>​	<code>Source是负责接收数据到Flume Agent的组件</code>。Source组件可以处理各种类型、各种格式的日志数据，包括avro、thrift、<code>exec</code>、jms、<code>spooling directory</code>、netcat、sequence generator、syslog、http、legacy。</p><p>:three:Channel</p><p>​	<code>Channel是位于Source和Sink之间的缓冲区</code>。因此，Channel允许Source和Sink运作在不同的速率上。Channel是线程安全的，可以同时处理几个Source的写入操作和几个Sink的读取操作。</p><p>​	Flume自带两种Channel：Memory Channel和File Channel。</p><p>​	<code>Memory Channel是内存中的队列。Memory Channel在不需要关心数据丢失的情景下适用</code>。如果需要关心数据丢失，那么Memory Channel就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。</p><p>File Channel将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。</p><p>:four:Sink</p><p>​	<code>Sink不断地轮询Channel中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个Flume Agent。</code></p><p>​	<code>Sink是完全事务性的</code>。在从Channel批量删除数据之前，每个Sink用Channel启动一个事务。批量事件一旦成功写出到存储系统或下一个Flume Agent，Sink就利用Channel提交事务。事务一旦被提交，该Channel从自己的内部缓冲区删除事件。</p><p>​	Sink组件目的地包括hdfs、logger、avro、thrift、ipc、file、null、HBase、solr、自定义。</p><p>:five:Event</p><p>​	传输单元，Flume数据传输的基本单元，以事件的形式将数据从源头送至目的地。</p><h3 id="1-3-Flume拓扑结构"><a href="#1-3-Flume拓扑结构" class="headerlink" title="1.3 Flume拓扑结构"></a>1.3 Flume拓扑结构</h3><p>Flume的拓扑结构如图1-3、1-4、1-5和1-6所示：</p><blockquote><p>图1-3 Flume Agent连接:</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141454646.png" alt="image-20240114145418597"></p><blockquote><p>图1-4 单source，多channel、sink:</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141454051.png" alt="image-20240114145425994"></p><blockquote><p>图1-5 Flume负载均衡:</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141455307.png" alt="image-20240114145522248"></p><blockquote><p>图1-6 Flume Agent聚合</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141457787.png" alt="image-20240114145705707"></p><h3 id="1-4-Flume-Agent内部原理"><a href="#1-4-Flume-Agent内部原理" class="headerlink" title="1.4 Flume Agent内部原理"></a>1.4 Flume Agent内部原理</h3><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141458659.png" alt="image-20240114145814594"></p><h2 id="2-快速入门"><a href="#2-快速入门" class="headerlink" title="2. 快速入门"></a>2. 快速入门</h2><h3 id="2-1-Flume安装地址"><a href="#2-1-Flume安装地址" class="headerlink" title="2.1 Flume安装地址"></a>2.1 Flume安装地址</h3><p>Flume官网地址:	<a target="_blank" rel="noopener" href="http://flume.apache.org/">http://flume.apache.org/</a></p><p>文档查看地址:	<a target="_blank" rel="noopener" href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></p><p>下载地址:	<a target="_blank" rel="noopener" href="http://archive.apache.org/dist/flume/">http://archive.apache.org/dist/flume/</a></p><h3 id="2-2-安装部署"><a href="#2-2-安装部署" class="headerlink" title="2.2 安装部署"></a>2.2 安装部署</h3><h4 id="2-2-1-将所需包解压重命名"><a href="#2-2-1-将所需包解压重命名" class="headerlink" title="2.2.1 将所需包解压重命名"></a>2.2.1 将所需包解压重命名</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># tar -zxvf /opt/software/apache-flume-1.9.0-bin.tar.gz -C /opt/module/</span>
<span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># mv /opt/module/apache-flume-1.9.0-bin/ /opt/module/apache-flume-1.9.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="2-2-2-添加环境变量"><a href="#2-2-2-添加环境变量" class="headerlink" title="2.2.2 添加环境变量"></a>2.2.2 添加环境变量</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># vi /etc/profile</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下内容:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#FLUME_HOME</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">FLUME_HOME</span><span class="token operator">=</span>/opt/module/apache-flume-1.9.0
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$FLUME_HOME</span>/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="2-2-3-修改配置"><a href="#2-2-3-修改配置" class="headerlink" title="2.2.3 修改配置"></a>2.2.3 修改配置</h4><blockquote><p>修改flume-env.sh 指定JDK</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># cp $FLUME_HOME/conf/flume-env.sh.template $FLUME_HOME/conf/flume-env.sh</span>
<span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># vi $FLUME_HOME/conf/flume-env.sh</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>修改如下:<img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141506629.png" alt="image-20240114150616554"></p><h4 id="2-2-4-解决guava冲突问题"><a href="#2-2-4-解决guava冲突问题" class="headerlink" title="2.2.4 解决guava冲突问题"></a>2.2.4 解决<strong>guava</strong>冲突问题</h4><p>将hadoop的guava包替换掉flume的guava包</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># rm -rf $FLUME_HOME/lib/guava-11.0.2.jar</span>
<span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># cp $HADOOP_HOME/share/hadoop/common/lib/guava-27.0-jre.jar $FLUME_HOME/lib/</span>

查看结果:
<span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># ll /opt/module/apache-flume-1.9.0/lib/ |grep guava</span>
-rw-r--r-- <span class="token number">1</span> root root <span class="token number">2747878</span> Jan <span class="token number">14</span> 07:09 guava-27.0-jre.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>运行命令(配置文件需自己进行编写)：</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">flume-ng agent <span class="token parameter variable">-n</span> a1 <span class="token parameter variable">-c</span> <span class="token variable">$FLUME_HOME</span>/conf <span class="token parameter variable">-f</span> <span class="token variable">$FLUME_HOME</span>/jobs/namenode-hdfs.conf <span class="token parameter variable">-Dflume.root.logger</span><span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>命令解析：</p><ul><li><p>-n&#x2F;–name 指定Agent的名称。（必填）</p></li><li><p>-c&#x2F;–conf 指定配置文件放在什么目录</p></li><li><p>-f&#x2F;–conf-file指定配置文件，必须在–c参数定义的目录下。（必填）</p></li><li><p>-Dflume.root.logger&#x3D;INFO,console 仅为 debug使用，请勿生产环境生搬硬套，否则大量的日志会返回到终端，将日志输入到控制台上</p></li></ul><p>#端口测试 netcat_flume_console.comf</p><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">a1<span class="token punctuation">.</span>sources = r1
a1<span class="token punctuation">.</span>sinks = k1
a1<span class="token punctuation">.</span>channels = c1

a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span><span class="token function">type</span> = netcat
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>bind = localhost
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>port = 9999

a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span><span class="token function">type</span> =logger

a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span><span class="token function">type</span> = memory
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>capacity = 1000
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>transactionCapacity = 100

a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>channels = c1
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>channel = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>#使用flume将数据导入到hdfs中</p><pre class="line-numbers language-none"><code class="language-none">a1.sources &#x3D; s1
a1.channels &#x3D; c1
a1.sinks &#x3D; k1

a1.sources.s1.type &#x3D; spooldir

a1.sources.s1.spoolDir  该目录下的文件会传输到HDFS

a1.sources.s1.spoolDir &#x3D; &#x2F;opt&#x2F;module&#x2F;flume&#x2F;tmpdata

a1.sinks.k1.type &#x3D; hdfs
a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;master:9000&#x2F;tmp&#x2F;flume&#x2F;logs

a1.channels.c1.type &#x3D; memory

a1.sources.s1.channels &#x3D; c1
a1.sinks.k1.channel &#x3D; c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>传输Hadoop日志(namenode)到hdfs:star:</p></blockquote><pre class="line-numbers language-none"><code class="language-none">a1.sources &#x3D; r1
a1.sinks &#x3D; k1
a1.channels &#x3D; c1

#读取位置
#定义sourece类型为exec可执行命令的
a1.sources.r1.type &#x3D; exec
a1.sources.r1.command &#x3D; tail -f &#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;logs&#x2F;hadoop-root-datanode-master.log

#存储位置
a1.sinks.k1.type &#x3D; hdfs
a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;master:9000&#x2F;tmp&#x2F;flume

#使用在内存中缓冲事件的通道

a1.channels.c1.type &#x3D; memory
a1.channels.c1.capacity &#x3D; 1000
a1.channels.c1.transactionCapacity &#x3D; 100

#将source和sink绑定到channel

a1.sources.r1.channels &#x3D; c1
a1.sinks.k1.channel &#x3D; c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>查看HDFS中&#x2F;tmp&#x2F;flume目录下生成的内容，将查看命令及结果（<code>至少5条结果</code>）</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hdfs dfs <span class="token parameter variable">-ls</span> /tmp/flume<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="C:/Users/Administrator/AppData/Roaming/Typora/typora-user-images/image-20240722170111746.png" alt="image-20240722170111746"></p><blockquote><p>报错解决：</p></blockquote><p><img src="https://gitee.com/master_hj/pic/raw/master/img/image-20230322121147277.png" alt="image-20230322121147277"></p><p>原因：<strong>guava</strong>冲突</p><p>解决：将&#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;guava-27.0-jre.jar 拷贝到 flume&#x2F;lib 中，并删除或把自带的 guava-11.0.2.jar 改名</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cp</span> <span class="token variable">$HADOOP_HOME</span>/share/hadoop/common/lib/guava-27.0-jre.jar <span class="token variable">$FLUME_HOME</span>/lib<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-企业开发案例"><a href="#3-企业开发案例" class="headerlink" title="3. 企业开发案例"></a>3. 企业开发案例</h2><h3 id="3-1-监控端口数据官方案例"><a href="#3-1-监控端口数据官方案例" class="headerlink" title="3.1 监控端口数据官方案例"></a>3.1 监控端口数据官方案例</h3><h4 id="3-1-1-案例需求："><a href="#3-1-1-案例需求：" class="headerlink" title="3.1.1 案例需求："></a>3.1.1 <strong>案例需求：</strong></h4><p>​	首先，Flume监控本机44444端口，然后通过telnet工具向本机44444端口发送消息，最后Flume将监听的数据实时显示在控制台</p><h4 id="3-1-2-需求分析"><a href="#3-1-2-需求分析" class="headerlink" title="3.1.2 需求分析"></a>3.1.2 <strong>需求分析</strong></h4><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141516353.png" alt="image-20240114151624267"></p><h4 id="3-1-3-实现步骤"><a href="#3-1-3-实现步骤" class="headerlink" title="3.1.3 实现步骤:"></a>3.1.3 <strong>实现步骤:</strong></h4><blockquote><p>1.安装telnet工具</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># yum install telnet -y</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>2.判断44444端口是否被占用</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># ss -tunlp |grep 44444</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>返回空值则表示没有被占用:</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141527659.png" alt="image-20240114152740603"></p><p>功能描述：ss命令是一个监控TCP&#x2F;IP网络的非常有用的工具，它可以显示路由表、实际的网络连接以及每一个网络接口设备的状态信息。</p><blockquote><p>3.创建Flume Agent配置文件flume-telnet-logger.conf</p></blockquote><p>(1) 在flume目录下创建job文件夹并进入job文件夹</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># mkdir $FLUME_HOME/job</span>
<span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># cd $FLUME_HOME/job</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(2) 在job文件夹下创建Flume Agent配置文件flume-telnet-logger.conf</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># vim flume-telnet-logger.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下内容:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Name the components on this agent</span>
a1.sources <span class="token operator">=</span> r1
a1.sinks <span class="token operator">=</span> k1
a1.channels <span class="token operator">=</span> c1

<span class="token comment"># Describe/configure the source</span>
a1.sources.r1.type <span class="token operator">=</span> netcat
a1.sources.r1.bind <span class="token operator">=</span> localhost
a1.sources.r1.port <span class="token operator">=</span> <span class="token number">44444</span>

<span class="token comment"># Describe the sink</span>
a1.sinks.k1.type <span class="token operator">=</span> logger

<span class="token comment"># Use a channel which buffers events in memory</span>
a1.channels.c1.type <span class="token operator">=</span> memory
a1.channels.c1.capacity <span class="token operator">=</span> <span class="token number">1000</span>
a1.channels.c1.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>

<span class="token comment"># Bind the source and sink to the channel</span>
a1.sources.r1.channels <span class="token operator">=</span> c1
a1.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：配置文件来源于官方手册<a target="_blank" rel="noopener" href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></p><p>本地官方文档：<code>/opt/module/apache-flume-1.9.0/docs/FlumeUserGuide.html</code></p><p>参数解释:<img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141535771.png" alt="image-20240114153507695"></p><p>:star:注意：一个<code>sources</code>可以对多个<code>channels</code>，一个<code>sinks</code>只能对接一个<code>channel</code></p><blockquote><p>4.开启flume监听端口</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># flume-ng agent -n a1 -c $FLUME_HOME/conf -f $FLUME_HOME/job/flume-telnet-logger.conf -Dflume.root.logger=INFO,console</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这是用于启动Flume代理（agent）的命令，以下是每个参数的解释：</p><ul><li><code>flume-ng</code>：Flume的命令行工具。</li><li><code>agent</code>：指定要运行的Flume代理。</li><li><code>-n a1</code>：指定代理的名称为<code>a1</code>。这是代理的唯一标识符。</li><li><code>-c $FLUME_HOME/conf</code>：指定Flume配置文件的目录。这里使用了环境变量 <code>$FLUME_HOME</code>，它应该设置为 Flume 的主目录。</li><li><code>-f $FLUME_HOME/jobs/namenode-hdfs.conf</code>：指定Flume代理使用的配置文件的路径。这个配置文件描述了数据流的配置，例如来源、通道和目的地。</li><li><code>-Dflume.root.logger=INFO,console</code>：设置Flume代理的日志级别和日志输出方式。在这个例子中，日志级别设置为<code>INFO</code>，并将日志输出到控制台（console）。</li></ul><p>运行结果如下:</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141548905.png" alt="image-20240114154810826"></p><blockquote><p>5.使用telnet工具向本机的44444端口发送内容</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># telnet localhost 44444</span>
Trying <span class="token number">127.0</span>.0.1<span class="token punctuation">..</span>.
Connected to localhost.
Escape character is <span class="token string">'^]'</span><span class="token builtin class-name">.</span>
hello
OK
this is bigdata
OK<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>6．在Flume监听页面观察接收数据情况</p></blockquote><p>结果如下:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">2024</span>-01-14 07:49:43,343 <span class="token punctuation">(</span>SinkRunner-PollingRunner-DefaultSinkProcessor<span class="token punctuation">)</span> <span class="token punctuation">[</span>INFO - org.apache.flume.sink.LoggerSink.process<span class="token punctuation">(</span>LoggerSink.java:95<span class="token punctuation">)</span><span class="token punctuation">]</span> Event: <span class="token punctuation">&#123;</span> headers:<span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span> body: <span class="token number">68</span> <span class="token number">65</span> 6C 6C 6F 0D                               hello. <span class="token punctuation">&#125;</span>
<span class="token number">2024</span>-01-14 07:49:59,039 <span class="token punctuation">(</span>SinkRunner-PollingRunner-DefaultSinkProcessor<span class="token punctuation">)</span> <span class="token punctuation">[</span>INFO - org.apache.flume.sink.LoggerSink.process<span class="token punctuation">(</span>LoggerSink.java:95<span class="token punctuation">)</span><span class="token punctuation">]</span> Event: <span class="token punctuation">&#123;</span> headers:<span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span> body: <span class="token number">74</span> <span class="token number">68</span> <span class="token number">69</span> <span class="token number">73</span> <span class="token number">20</span> <span class="token number">69</span> <span class="token number">73</span> <span class="token number">20</span> <span class="token number">62</span> <span class="token number">69</span> <span class="token number">67</span> <span class="token number">64</span> <span class="token number">61</span> <span class="token number">74</span> <span class="token number">61</span> 0D this is bigdata. <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141551652.png" alt="image-20240114155118565"></p><h3 id="3-2-实时读取本地文件到HDFS案例-缺少jar包待测试"><a href="#3-2-实时读取本地文件到HDFS案例-缺少jar包待测试" class="headerlink" title="3.2 实时读取本地文件到HDFS案例(缺少jar包待测试)"></a>3.2 实时读取本地文件到HDFS案例(<code>缺少jar包待测试</code>)</h3><h4 id="3-2-1-案例需求："><a href="#3-2-1-案例需求：" class="headerlink" title="3.2.1 案例需求："></a>3.2.1 案例需求：</h4><p>​	实时监控Hive日志，并上传到HDFS中</p><h4 id="3-2-2-需求分析："><a href="#3-2-2-需求分析：" class="headerlink" title="3.2.2 需求分析："></a>3.2.2 需求分析：</h4><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141553681.png" alt="image-20240114155345612"></p><h4 id="3-2-3-实现步骤："><a href="#3-2-3-实现步骤：" class="headerlink" title="3.2.3 实现步骤："></a>3.2.3 实现步骤：</h4><blockquote><p>1.Flume要想将数据输出到HDFS，必须持有Hadoop相关jar包</p></blockquote><p>将commons-configuration-1.6.jar、</p><p>hadoop-auth-2.7.2.jar、</p><p>hadoop-common-2.7.2.jar、</p><p>hadoop-hdfs-2.7.2.jar、</p><p>commons-io-2.4.jar、</p><p>htrace-core-3.1.0-incubating.jar</p><p>拷贝到&#x2F;opt&#x2F;module&#x2F;flume&#x2F;lib文件夹下</p><blockquote><p>2.创建flume-file-hdfs.conf文件</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># vim flume-file-hdfs.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下内容:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Name the components on this agent</span>
a2.sources <span class="token operator">=</span> r2
a2.sinks <span class="token operator">=</span> k2
a2.channels <span class="token operator">=</span> c2

<span class="token comment"># Describe/configure the source</span>
a2.sources.r2.type <span class="token operator">=</span> <span class="token builtin class-name">exec</span>
a2.sources.r2.command <span class="token operator">=</span> <span class="token function">tail</span> <span class="token parameter variable">-F</span> /opt/module/hive/logs/hive.log
a2.sources.r2.shell <span class="token operator">=</span> /bin/bash <span class="token parameter variable">-c</span>

<span class="token comment"># Describe the sink</span>
a2.sinks.k2.type <span class="token operator">=</span> hdfs
a2.sinks.k2.hdfs.path <span class="token operator">=</span> hdfs://master:9000/flume/%Y%m%d/%H
<span class="token comment">#上传文件的前缀</span>
a2.sinks.k2.hdfs.filePrefix <span class="token operator">=</span> logs-
<span class="token comment">#是否按照时间滚动文件夹</span>
a2.sinks.k2.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment">#多少时间单位创建一个新的文件夹</span>
a2.sinks.k2.hdfs.roundValue <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment">#重新定义时间单位</span>
a2.sinks.k2.hdfs.roundUnit <span class="token operator">=</span> hour
<span class="token comment">#是否使用本地时间戳</span>
a2.sinks.k2.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment">#积攒多少个Event才flush到HDFS一次</span>
a2.sinks.k2.hdfs.batchSize <span class="token operator">=</span> <span class="token number">1000</span>
<span class="token comment">#设置文件类型，可支持压缩</span>
a2.sinks.k2.hdfs.fileType <span class="token operator">=</span> DataStream
<span class="token comment">#多久生成一个新的文件</span>
a2.sinks.k2.hdfs.rollInterval <span class="token operator">=</span> <span class="token number">600</span>
<span class="token comment">#设置每个文件的滚动大小</span>
a2.sinks.k2.hdfs.rollSize <span class="token operator">=</span> <span class="token number">134217700</span>
<span class="token comment">#文件的滚动与Event数量无关</span>
a2.sinks.k2.hdfs.rollCount <span class="token operator">=</span> <span class="token number">0</span>
<span class="token comment">#最小冗余数</span>
a2.sinks.k2.hdfs.minBlockReplicas <span class="token operator">=</span> <span class="token number">1</span>

<span class="token comment"># Use a channel which buffers events in memory</span>
a2.channels.c2.type <span class="token operator">=</span> memory
a2.channels.c2.capacity <span class="token operator">=</span> <span class="token number">1000</span>
a2.channels.c2.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>

<span class="token comment"># Bind the source and sink to the channel</span>
a2.sources.r2.channels <span class="token operator">=</span> c2
a2.sinks.k2.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>参数解释:<img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141608410.png" alt="image-20240114160805326"></p><blockquote><p>3.执行监控配置</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master apache-flume-1.9.0<span class="token punctuation">]</span><span class="token comment"># flume-ng agent --conf conf/ --name a2 --conf-file job/flume-file-hdfs.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>4.开启Hadoop和Hive并操作Hive产生日志</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master hadoop<span class="token punctuation">]</span>$ sbin/start-dfs.sh
<span class="token punctuation">[</span>root@master hadoop<span class="token punctuation">]</span>$ sbin/start-yarn.sh

<span class="token punctuation">[</span>root@master hive<span class="token punctuation">]</span>$ bin/hive
hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>5.在HDFS上查看文件。</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141611859.png" alt="image-20240114161137794"></p><h3 id="3-3-实时读取目录文件到HDFS案例"><a href="#3-3-实时读取目录文件到HDFS案例" class="headerlink" title="3.3 实时读取目录文件到HDFS案例"></a>3.3 实时读取目录文件到HDFS案例</h3><h4 id="3-3-1-案例需求："><a href="#3-3-1-案例需求：" class="headerlink" title="3.3.1 案例需求："></a>3.3.1 案例需求：</h4><p>​	使用Flume监听整个目录的文件</p><h4 id="3-3-2-需求分析"><a href="#3-3-2-需求分析" class="headerlink" title="3.3.2 需求分析"></a>3.3.2 需求分析</h4><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141613033.png" alt="image-20240114161315952"></p><h4 id="3-3-3-实现步骤"><a href="#3-3-3-实现步骤" class="headerlink" title="3.3.3 实现步骤"></a>3.3.3 实现步骤</h4><blockquote><p>1.创建配置文件flume-dir-hdfs.conf</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># mkdir /opt/module/apache-flume-1.9.0/upload</span>
<span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># vim flume-dir-hdfs.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>添加以下内容:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">a3.sources <span class="token operator">=</span> r3
a3.sinks <span class="token operator">=</span> k3
a3.channels <span class="token operator">=</span> c3

<span class="token comment"># Describe/configure the source</span>
a3.sources.r3.type <span class="token operator">=</span> spooldir
a3.sources.r3.spoolDir <span class="token operator">=</span> /opt/module/apache-flume-1.9.0/upload
a3.sources.r3.fileSuffix <span class="token operator">=</span> .COMPLETED
a3.sources.r3.fileHeader <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment">#忽略所有以.tmp结尾的文件，不上传</span>
a3.sources.r3.ignorePattern <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>^ <span class="token punctuation">]</span>*<span class="token punctuation">\</span>.tmp<span class="token punctuation">)</span>

<span class="token comment"># Describe the sink</span>
a3.sinks.k3.type <span class="token operator">=</span> hdfs
a3.sinks.k3.hdfs.path <span class="token operator">=</span> hdfs://master:9000/apache-flume-1.9.0/upload/%Y%m%d/%H
<span class="token comment">#上传文件的前缀</span>
a3.sinks.k3.hdfs.filePrefix <span class="token operator">=</span> upload-
<span class="token comment">#是否按照时间滚动文件夹</span>
a3.sinks.k3.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment">#多少时间单位创建一个新的文件夹</span>
a3.sinks.k3.hdfs.roundValue <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment">#重新定义时间单位</span>
a3.sinks.k3.hdfs.roundUnit <span class="token operator">=</span> hour
<span class="token comment">#是否使用本地时间戳</span>
a3.sinks.k3.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment">#积攒多少个Event才flush到HDFS一次</span>
a3.sinks.k3.hdfs.batchSize <span class="token operator">=</span> <span class="token number">100</span>
<span class="token comment">#设置文件类型，可支持压缩</span>
a3.sinks.k3.hdfs.fileType <span class="token operator">=</span> DataStream
<span class="token comment">#多久生成一个新的文件</span>
a3.sinks.k3.hdfs.rollInterval <span class="token operator">=</span> <span class="token number">600</span>
<span class="token comment">#设置每个文件的滚动大小大概是128M</span>
a3.sinks.k3.hdfs.rollSize <span class="token operator">=</span> <span class="token number">134217700</span>
<span class="token comment">#文件的滚动与Event数量无关</span>
a3.sinks.k3.hdfs.rollCount <span class="token operator">=</span> <span class="token number">0</span>
<span class="token comment">#最小冗余数</span>
a3.sinks.k3.hdfs.minBlockReplicas <span class="token operator">=</span> <span class="token number">1</span>

<span class="token comment"># Use a channel which buffers events in memory</span>
a3.channels.c3.type <span class="token operator">=</span> memory
a3.channels.c3.capacity <span class="token operator">=</span> <span class="token number">1000</span>
a3.channels.c3.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>

<span class="token comment"># Bind the source and sink to the channel</span>
a3.sources.r3.channels <span class="token operator">=</span> c3
a3.sinks.k3.channel <span class="token operator">=</span> c3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>参数详解:<img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141616579.png" alt="image-20240114161617490"></p><blockquote><p>2.启动监控文件夹命令</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># flume-ng agent -n a3 -c $FLUME_HOME/conf -f $FLUME_HOME/job/flume-dir-hdfs.conf -Dflume.root.logger=INFO,console</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>说明</code>： 在使用Spooling Directory Source时</p><ul><li>不要在监控目录中创建并持续修改文件</li><li>上传完成的文件会以.COMPLETED结尾</li><li>被监控文件夹每500毫秒扫描一次文件变动</li></ul><blockquote><p>3.向upload文件夹中添加文件</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master upload<span class="token punctuation">]</span><span class="token comment"># touch hj.txt</span>
<span class="token punctuation">[</span>root@master upload<span class="token punctuation">]</span><span class="token comment"># touch app.txt</span>
<span class="token punctuation">[</span>root@master upload<span class="token punctuation">]</span><span class="token comment"># touch hyp.txt</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>查看flume日志输出:</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141630390.png" alt="image-20240114163056295"></p><blockquote><p>4.查看HDFS上的数据</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141631755.png" alt="image-20240114163156670"></p><blockquote><p>5.等待1s，再次查询upload文件夹</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master upload<span class="token punctuation">]</span><span class="token comment"># ll</span>
total <span class="token number">0</span>
-rw-r--r-- <span class="token number">1</span> root root <span class="token number">0</span> Jan <span class="token number">14</span> 08:28 app.txt.COMPLETED
-rw-r--r-- <span class="token number">1</span> root root <span class="token number">0</span> Jan <span class="token number">14</span> 08:28 hj.txt.COMPLETED
-rw-r--r-- <span class="token number">1</span> root root <span class="token number">0</span> Jan <span class="token number">14</span> 08:28 hyp.txt.COMPLETED<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-4-单数据源多出口案例-选择器"><a href="#3-4-单数据源多出口案例-选择器" class="headerlink" title="3.4 单数据源多出口案例(选择器)"></a>3.4 单数据源多出口案例(选择器)</h3><p>单Source多Channel、Sink如下图所示:</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141635879.png" alt="image-20240114163500795"></p><h4 id="3-4-1-案例需求："><a href="#3-4-1-案例需求：" class="headerlink" title="3.4.1 案例需求："></a>3.4.1 案例需求：</h4><p>​	使用Flume-1监控文件变动，Flume-1将变动内容传递给Flume-2，Flume-2负责存储到HDFS。同时Flume-1将变动内容传递给Flume-3，Flume-3负责输出到Local FileSystem。</p><h4 id="3-4-2-需求分析"><a href="#3-4-2-需求分析" class="headerlink" title="3.4.2 需求分析"></a>3.4.2 需求分析</h4><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141636677.png" alt="image-20240114163605599"></p><h4 id="3-4-3-实现步骤："><a href="#3-4-3-实现步骤：" class="headerlink" title="3.4.3 实现步骤："></a>3.4.3 实现步骤：</h4><blockquote><p>1.准备工作</p></blockquote><p>在&#x2F;opt&#x2F;module&#x2F;flume&#x2F;job目录下创建group1文件夹</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># mkdir $FLUME_HOME/job/group1</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在&#x2F;opt&#x2F;module&#x2F;datas&#x2F;目录下创建flume3文件夹</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /opt/module/datas/flume3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>2.创建flume-file-flume.conf</p></blockquote><p>​	配置1个接收日志文件的source和两个channel、两个sink，分别输送给flume-flume-hdfs和flume-flume-dir。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># cd group1/</span>
<span class="token punctuation">[</span>root@master group1<span class="token punctuation">]</span><span class="token comment"># vim flume-file-flume.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>添加以下内容:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Name the components on this agent</span>
a1.sources <span class="token operator">=</span> r1
a1.sinks <span class="token operator">=</span> k1 k2
a1.channels <span class="token operator">=</span> c1 c2
<span class="token comment"># 将数据流复制给所有channel</span>
a1.sources.r1.selector.type <span class="token operator">=</span> replicating

<span class="token comment"># Describe/configure the source</span>
a1.sources.r1.type <span class="token operator">=</span> <span class="token builtin class-name">exec</span>
a1.sources.r1.command <span class="token operator">=</span> <span class="token function">tail</span> <span class="token parameter variable">-F</span> /opt/module/apache-hive-3.1.2/logs/hiveServer2.log
a1.sources.r1.shell <span class="token operator">=</span> /bin/bash <span class="token parameter variable">-c</span>

<span class="token comment"># Describe the sink</span>
a1.sinks.k1.type <span class="token operator">=</span> avro
a1.sinks.k1.hostname <span class="token operator">=</span> master 
a1.sinks.k1.port <span class="token operator">=</span> <span class="token number">4141</span>

a1.sinks.k2.type <span class="token operator">=</span> avro
a1.sinks.k2.hostname <span class="token operator">=</span> master
a1.sinks.k2.port <span class="token operator">=</span> <span class="token number">4142</span>

<span class="token comment"># Describe the channel</span>
a1.channels.c1.type <span class="token operator">=</span> memory
a1.channels.c1.capacity <span class="token operator">=</span> <span class="token number">1000</span>
a1.channels.c1.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>

a1.channels.c2.type <span class="token operator">=</span> memory
a1.channels.c2.capacity <span class="token operator">=</span> <span class="token number">1000</span>
a1.channels.c2.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>

<span class="token comment"># Bind the source and sink to the channel</span>
a1.sources.r1.channels <span class="token operator">=</span> c1 c2
a1.sinks.k1.channel <span class="token operator">=</span> c1
a1.sinks.k2.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>注</code>：Avro是由Hadoop创始人Doug Cutting创建的一种语言无关的数据序列化和RPC框架。</p><p><code>注</code>：RPC（Remote Procedure Call）—远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。</p><blockquote><p>3.创建flume-flume-hdfs.conf</p></blockquote><p>配置上级Flume输出的Source，输出是到HDFS的Sink。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master group1<span class="token punctuation">]</span><span class="token comment"># vim flume-flume-hdfs.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下内容:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Name the components on this agent</span>
a2.sources <span class="token operator">=</span> r1
a2.sinks <span class="token operator">=</span> k1
a2.channels <span class="token operator">=</span> c1

<span class="token comment"># Describe/configure the source</span>
a2.sources.r1.type <span class="token operator">=</span> avro
a2.sources.r1.bind <span class="token operator">=</span> master
a2.sources.r1.port <span class="token operator">=</span> <span class="token number">4141</span>

<span class="token comment"># Describe the sink</span>
a2.sinks.k1.type <span class="token operator">=</span> hdfs
a2.sinks.k1.hdfs.path <span class="token operator">=</span> hdfs://master:9000/flume2/%Y%m%d/%H
<span class="token comment">#上传文件的前缀</span>
a2.sinks.k1.hdfs.filePrefix <span class="token operator">=</span> flume2-
<span class="token comment">#是否按照时间滚动文件夹</span>
a2.sinks.k1.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment">#多少时间单位创建一个新的文件夹</span>
a2.sinks.k1.hdfs.roundValue <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment">#重新定义时间单位</span>
a2.sinks.k1.hdfs.roundUnit <span class="token operator">=</span> hour
<span class="token comment">#是否使用本地时间戳</span>
a2.sinks.k1.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment">#积攒多少个Event才flush到HDFS一次</span>
a2.sinks.k1.hdfs.batchSize <span class="token operator">=</span> <span class="token number">100</span>
<span class="token comment">#设置文件类型，可支持压缩</span>
a2.sinks.k1.hdfs.fileType <span class="token operator">=</span> DataStream
<span class="token comment">#多久生成一个新的文件</span>
a2.sinks.k1.hdfs.rollInterval <span class="token operator">=</span> <span class="token number">600</span>
<span class="token comment">#设置每个文件的滚动大小大概是128M</span>
a2.sinks.k1.hdfs.rollSize <span class="token operator">=</span> <span class="token number">134217700</span>
<span class="token comment">#文件的滚动与Event数量无关</span>
a2.sinks.k1.hdfs.rollCount <span class="token operator">=</span> <span class="token number">0</span>
<span class="token comment">#最小冗余数</span>
a2.sinks.k1.hdfs.minBlockReplicas <span class="token operator">=</span> <span class="token number">1</span>

<span class="token comment"># Describe the channel</span>
a2.channels.c1.type <span class="token operator">=</span> memory
a2.channels.c1.capacity <span class="token operator">=</span> <span class="token number">1000</span>
a2.channels.c1.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>

<span class="token comment"># Bind the source and sink to the channel</span>
a2.sources.r1.channels <span class="token operator">=</span> c1
a2.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>4.创建flume-flume-dir.conf</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master group1<span class="token punctuation">]</span><span class="token comment"># vim flume-flume-dir.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下内容:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Name the components on this agent</span>
a3.sources <span class="token operator">=</span> r1
a3.sinks <span class="token operator">=</span> k1
a3.channels <span class="token operator">=</span> c2

<span class="token comment"># Describe/configure the source</span>
a3.sources.r1.type <span class="token operator">=</span> avro
a3.sources.r1.bind <span class="token operator">=</span> master
a3.sources.r1.port <span class="token operator">=</span> <span class="token number">4142</span>

<span class="token comment"># Describe the sink</span>
a3.sinks.k1.type <span class="token operator">=</span> file_roll
a3.sinks.k1.sink.directory <span class="token operator">=</span> /opt/module/datas/flume3

<span class="token comment"># Describe the channel</span>
a3.channels.c2.type <span class="token operator">=</span> memory
a3.channels.c2.capacity <span class="token operator">=</span> <span class="token number">1000</span>
a3.channels.c2.transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>

<span class="token comment"># Bind the source and sink to the channel</span>
a3.sources.r1.channels <span class="token operator">=</span> c2
a3.sinks.k1.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>提示：输出的本地目录<code>必须是已经存在的目录</code>，如果该目录不存在，并不会创建新的目录。</p><blockquote><p>5.执行配置文件</p></blockquote><p>别开启对应配置文件：<code>flume-flume-dir</code>，<code>flume-flume-hdfs</code>，<code>flume-file-flume</code>。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">1</span>.
flume-ng agent <span class="token parameter variable">-c</span> <span class="token variable">$FLUME_HOME</span>/conf <span class="token parameter variable">-n</span> a3 <span class="token parameter variable">-f</span> <span class="token variable">$FLUME_HOME</span>/job/group1/flume-flume-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141741088.png" alt="image-20240114174121978"></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">2</span>.
flume-ng agent <span class="token parameter variable">-c</span> <span class="token variable">$FLUME_HOME</span>/conf <span class="token parameter variable">-n</span> a2 <span class="token parameter variable">-f</span> <span class="token variable">$FLUME_HOME</span>/job/group1/flume-flume-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141742761.png" alt="image-20240114174151299"></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">3</span>.
flume-ng agent <span class="token parameter variable">-c</span> <span class="token variable">$FLUME_HOME</span>/conf <span class="token parameter variable">-n</span> a1 <span class="token parameter variable">-f</span> <span class="token variable">$FLUME_HOME</span>/job/group1/flume-file-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141742034.png" alt="image-20240114174226938"></p><blockquote><p>6.启动hive</p></blockquote><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token punctuation">[</span>root<span class="token variable">@master</span> <span class="token operator">~</span><span class="token punctuation">]</span><span class="token comment"># hive</span>
hive<span class="token operator">></span> <span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span>
OK
<span class="token keyword">default</span>
<span class="token keyword">Time</span> taken: <span class="token number">0.469</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">1</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>7.检查HDFS上的数据</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401141747104.png" alt="image-20240114174659992"></p><blockquote><p>8.检查&#x2F;opt&#x2F;module&#x2F;datas&#x2F;flume3目录中数据</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master flume3<span class="token punctuation">]</span>$ ll
总用量 <span class="token number">8</span>
-rw-rw-r--. <span class="token number">1</span> root root <span class="token number">5942</span> <span class="token number">5</span>月  <span class="token number">22</span> 00:09 <span class="token number">1526918887550</span>-3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="3-4-4-大数据赛项数据采集"><a href="#3-4-4-大数据赛项数据采集" class="headerlink" title="3.4.4 大数据赛项数据采集"></a>3.4.4 大数据赛项数据采集</h4><h5 id="3-4-1-电商数据："><a href="#3-4-1-电商数据：" class="headerlink" title="3.4.1 电商数据："></a>3.4.1 电商数据：</h5><h6 id="3-4-4-1-1-任务一："><a href="#3-4-4-1-1-任务一：" class="headerlink" title="3.4.4.1.1 任务一："></a>3.4.4.1.1 任务一：</h6><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">在主节点使用Flume采集实时数据生成器10050端口的socket数据，将数据存入到Kafka的Topic中（Topic名称为order，分区数为4），使用Kafka自带的消费者消费order（Topic）中的数据，将前2条数据的结果截图粘贴至客户端桌面【Release\任务D提交结果<span class="token punctuation">.</span>docx】中对应的任务序号下；<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>1.创建bigdata.conf</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># vim bigdata.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下配置:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 定义这个agent中各组件的名字</span>
a1.sources <span class="token operator">=</span> r1
a1.sinks <span class="token operator">=</span> k1
a1.channels <span class="token operator">=</span> c1

<span class="token comment"># 描述和配置source组件：r1</span>
a1.sources.r1.type <span class="token operator">=</span> netcat
a1.sources.r1.bind <span class="token operator">=</span> <span class="token number">192.168</span>.1.10
a1.sources.r1.port <span class="token operator">=</span> <span class="token number">10050</span>
<span class="token comment"># 这条可忽略</span>
a1.sources.r1.max-line-length <span class="token operator">=</span> <span class="token number">102400</span>

<span class="token comment"># 描述和配置kafka sink组件：k1</span>
a1.sinks.k1.type <span class="token operator">=</span> org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.topic <span class="token operator">=</span> bigdata
a1.sinks.k1.kafka.bootstrap.servers <span class="token operator">=</span> master:9092,slave1:9092,slave2:9092
a1.sinks.kafka.flumeBatchSize <span class="token operator">=</span> <span class="token number">200</span>
a1.sinks.k1.kafka.producer.acks <span class="token operator">=</span> <span class="token number">1</span>
a1.sinks.k1.kafka.producer.linger.ms <span class="token operator">=</span> <span class="token number">1</span>
a1.sinks.k1.kafka.producer.compression.type <span class="token operator">=</span> snappy

<span class="token comment"># 描述和配置channel组件，此处使用是内存缓存的方式</span>
a1.channels.c1.type <span class="token operator">=</span> memory
a1.channels.c1.capacity <span class="token operator">=</span> <span class="token number">10000</span>
a1.channels.c1.transactionCapacity <span class="token operator">=</span> <span class="token number">1000</span>

<span class="token comment"># 描述和配置source  channel   sink之间的连接关系</span>
a1.sources.r1.channels <span class="token operator">=</span> c1
a1.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>:star::star: 配置参考<code>/opt/module/apache-flume-1.9.0/docs/FlumeUserGuide.html</code>：</p><p><strong>定义agent sources channel参考：</strong></p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191455205.png" alt="image-20240219145524126"></p><p>定义kafka sinks：</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191457461.png" alt="image-20240219145733401"></p><blockquote><p>启动zookeeper 和 kafka服务,并创建名为<code>bigdata</code>的topic</p></blockquote><p><strong>启动方式1（脚本启动）：</strong></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">1</span>.启动zookeeper服务
<span class="token punctuation">[</span>root@master ~<span class="token punctuation">]</span><span class="token comment"># zk.sh start</span>

<span class="token number">2</span>.启动kafka服务
<span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># kafka.sh start</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>启动方式2（命令行启动）：</strong></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">所有节点执行:
<span class="token number">1</span>.启动zookeeper服务
	zkServer.sh start

<span class="token number">2</span>.启动kafka服务
	kafka-server-start.sh <span class="token parameter variable">-daemon</span> <span class="token variable">$KAFKA_HOME</span>/config/server.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401142234874.png" alt="image-20240114223439773"></p><p>创建topic:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--zookeeper</span> master:2181,slave1:2181,slave2:2181 <span class="token parameter variable">--partitions</span> <span class="token number">3</span> --replication-factor <span class="token number">3</span> <span class="token parameter variable">--topic</span> bigdata<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看topic:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">kafka-topics.sh <span class="token parameter variable">--list</span> <span class="token parameter variable">--zookeeper</span> master:2181,slave1:2181,slave2:2181<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images/202401142252373.png" alt="image-20240114225212291"></p><blockquote><p>执行配置文件:</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">flume-ng agent <span class="token parameter variable">-n</span> a1 <span class="token parameter variable">-c</span> <span class="token variable">$FLUME_HOME</span>/conf <span class="token parameter variable">-f</span> <span class="token variable">$FLUME_HOME</span>/job/bigdata.conf <span class="token parameter variable">-Dflume.root.logger</span><span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行结果如下：</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191519701.png" alt="image-20240219151912630"></p><p>消费者消费消息:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">kafka-console-consumer.sh --bootstrap-server master:9092,slave1:9092,slave2:9092 <span class="token parameter variable">--topic</span> bigdata --from-beginning<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>运行结果：</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191522197.png" alt="image-20240219152257146"></p><blockquote><p>运行模拟数据脚本Python脚本：</p></blockquote><p>目录如下：<img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191524225.png" alt="image-20240219152423173"></p><p>编辑Python脚本，修改ip</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191525258.png" alt="image-20240219152522206"></p><p>修改后运行Python脚本：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">gxjzy@gxjzy:~/桌面/数据采集$ <span class="token function">sudo</span> python3 test2.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果如下：</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191526367.png" alt="image-20240219152630307"></p><p>观察kafka消费者：</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191527504.png" alt="image-20240219152704419"></p><p>完成</p><blockquote><p>使用Kafka自带的消费者消费order（Topic）中的数据，将前2条数据的结果截图:</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">kafka-console-consumer.sh --bootstrap-server bigdata1:9092 --from-beginning <span class="token parameter variable">--topic</span> order --max-messages <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="C:/Users/Administrator/AppData/Roaming/Typora/typora-user-images/image-20240722173635683.png" alt="image-20240722173635683"></p><h6 id="3-4-4-1-2-任务二"><a href="#3-4-4-1-2-任务二" class="headerlink" title="3.4.4.1.2 任务二:"></a>3.4.4.1.2 任务二:</h6><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">采用多路复用模式，Flume接收数据注入kafka 的同时，将数据备份到HDFS目录<span class="token operator">/</span>user/test/flumebackup下，将查看备份目录下的第一个文件的前2条数据的命令与结果截图粘贴至客户端桌面【Release\任务D提交结果<span class="token punctuation">.</span>docx】中对应的任务序号下。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>多路复用架构图：</strong></p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191644625.png" alt="image-20240219164419540"></p><blockquote><p>1.创建<code>bigdata_Multiplexing.conf</code>多路复用</p></blockquote><p>拷贝前面编写的配置文件，新加一个hdfs的sinks：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@master job<span class="token punctuation">]</span><span class="token comment"># cp bigdata.conf bigdata_Multiplexing.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改后内容如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 定义这个agent中各组件的名字</span>
a1.sources <span class="token operator">=</span> r1
a1.sinks <span class="token operator">=</span> k1 k2
a1.channels <span class="token operator">=</span> c1 c2

<span class="token comment"># 描述和配置source组件：r1</span>
a1.sources.r1.type <span class="token operator">=</span> netcat
a1.sources.r1.bind <span class="token operator">=</span> <span class="token number">192.168</span>.1.10
a1.sources.r1.port <span class="token operator">=</span> <span class="token number">10050</span>
a1.sources.r1.max-line-length <span class="token operator">=</span> <span class="token number">102400</span>

<span class="token comment"># 描述和配置sink组件：k1</span>
a1.sinks.k1.type <span class="token operator">=</span> org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.topic <span class="token operator">=</span> bigdata
a1.sinks.k1.kafka.bootstrap.servers <span class="token operator">=</span> master:9092,slave1:9092,slave2:9092
a1.sinks.kafka.flumeBatchSize <span class="token operator">=</span> <span class="token number">200</span>
a1.sinks.k1.kafka.producer.acks <span class="token operator">=</span> <span class="token number">1</span>
a1.sinks.k1.kafka.producer.linger.ms <span class="token operator">=</span> <span class="token number">1</span>
a1.sinks.k1.kafka.producer.compression.type <span class="token operator">=</span> snappy

<span class="token comment"># 描述和配置sink组件：k2</span>
<span class="token comment">## 指定了数据接收组件类型为 HDFS</span>
a1.sinks.k2.type <span class="token operator">=</span> hdfs
<span class="token comment">## 指定了写入 HDFS 的路径</span>
a1.sinks.k2.hdfs.path <span class="token operator">=</span> hdfs://master:9000/user/test/flumebackup
<span class="token comment">## 指定了每批次写入 HDFS 的记录数为 100</span>
a1.sinks.k2.hdfs.batchSize <span class="token operator">=</span> <span class="token number">100</span>
<span class="token comment">##指定了在滚动写入 HDFS 之前等待的最大文件大小为 10000 字节</span>
a1.sinks.k2.hdfs.rollSize <span class="token operator">=</span> <span class="token number">10000</span>

<span class="token comment"># 描述和配置channel组件，此处使用是内存缓存的方式 c1</span>
a1.channels.c1.type <span class="token operator">=</span> memory
a1.channels.c1.capacity <span class="token operator">=</span> <span class="token number">10000</span>
a1.channels.c1.transactionCapacity <span class="token operator">=</span> <span class="token number">1000</span>

<span class="token comment"># 描述和配置channel组件，此处使用是内存缓存的方式 c2</span>
a1.channels.c2.type <span class="token operator">=</span> memory
a1.channels.c2.capacity <span class="token operator">=</span> <span class="token number">10000</span>
a1.channels.c2.transactionCapacity <span class="token operator">=</span> <span class="token number">1000</span>

<span class="token comment"># 描述和配置source  channel   sink之间的连接关系</span>
a1.sources.r1.channels <span class="token operator">=</span> c1 c2
a1.sinks.k1.channel <span class="token operator">=</span> c1
a1.sinks.k2.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>主要添加配置如下：<img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191929098.png" alt="image-20240219192902016"></p><p>参考：</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402291639204.png" alt="image-20240229163920112"></p><p>启动flume服务：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">flume-ng agent <span class="token parameter variable">-n</span> a1 <span class="token parameter variable">-c</span> <span class="token variable">$FLUME_HOME</span>/conf <span class="token parameter variable">-f</span> <span class="token variable">$FLUME_HOME</span>/job/bigdata_Multiplexing.conf <span class="token parameter variable">-Dflume.root.logger</span><span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>运行结果：</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191927725.png" alt="image-20240219192723639"></p><blockquote><p>查看备份目录下的第一个文件的前2条数据的命令与结果截图:</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191924085.png" alt="image-20240219192431005"></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hdfs dfs <span class="token parameter variable">-cat</span> /usr/test/flumebackup/FlumeData.1708341766181 <span class="token operator">|</span> <span class="token function">head</span> <span class="token parameter variable">-n</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>消费者消费消息:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">kafka-console-consumer.sh --bootstrap-server master:9092,slave1:9092,slave2:9092 <span class="token parameter variable">--topic</span> bigdata --from-beginning<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>运行结果：<img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402191930921.png" alt="image-20240219193028843"></p><p>数据采集完成，接下来使用fink进行实时数据处理</p><h5 id="3-4-2-工业数据："><a href="#3-4-2-工业数据：" class="headerlink" title="3.4.2 工业数据："></a>3.4.2 工业数据：</h5><h6 id="3-4-2-1-任务一："><a href="#3-4-2-1-任务一：" class="headerlink" title="3.4.2.1 任务一："></a>3.4.2.1 任务一：</h6><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">1、在主节点使用Flume采集<span class="token operator">/</span>data_log目录下实时日志文件中的数据，将数据存入到Kafka的Topic中（Topic名称分别为ChangeRecord、ProduceRecord和EnvironmentData，分区数为4），将Flume采集ChangeRecord主题的配置截图粘贴至客户端桌面【Release\任务D提交结果<span class="token punctuation">.</span>docx】中对应的任务序号下；<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>创建topic：</p></blockquote><p>partitions:	分区</p><p>replication-factor：	副本</p><p><strong>ChangeRecord：</strong></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--zookeeper</span> master:2181,slave1:2181,slave2:2181 <span class="token parameter variable">--partitions</span> <span class="token number">4</span> --replication-factor <span class="token number">1</span> <span class="token parameter variable">--topic</span> ChangeRecord<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>ProduceRecord：</strong></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--zookeeper</span> master:2181,slave1:2181,slave2:2181 <span class="token parameter variable">--partitions</span> <span class="token number">4</span> --replication-factor <span class="token number">1</span> <span class="token parameter variable">--topic</span> ProduceRecord<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>EnvironmentData:</strong></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--zookeeper</span> master:2181,slave1:2181,slave2:2181 <span class="token parameter variable">--partitions</span> <span class="token number">4</span> --replication-factor <span class="token number">1</span> <span class="token parameter variable">--topic</span> EnvironmentData<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>创建后的topic如下：</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@bigdata1 data_log<span class="token punctuation">]</span><span class="token comment"># kafka-topics.sh --zookeeper localhost:2181 --list</span>
ChangeRecord
EnvironmentData
ProduceRecord<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402281035190.png" alt="image-20240228103535104"></p><blockquote><p>　创建industry.conf：</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@bigdata1 job<span class="token punctuation">]</span><span class="token comment"># vim industry.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加以下内容：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 定义这个agent中各组件的名字</span>
a1.sources <span class="token operator">=</span> r1 r2 r3
a1.sinks <span class="token operator">=</span> k1 k2 k3
a1.channels <span class="token operator">=</span> c1 c2 c3

<span class="token comment"># 定义sources r1</span>
a1.sources.r1.type <span class="token operator">=</span> TAILDIR
a1.sources.r1.positionFile <span class="token operator">=</span>/opt/module/flume-1.9.0/changerecord/taildir_position.json
a1.sources.r1.filegroups <span class="token operator">=</span> f1
a1.sources.r1.filegroups.f1 <span class="token operator">=</span> /data_log/.*changerecord.csv
<span class="token comment"># r2</span>
a1.sources.r2.type <span class="token operator">=</span> TAILDIR
a1.sources.r2.positionFile <span class="token operator">=</span> /opt/module/flume-1.9.0/producerecord/taildir_position.json
a1.sources.r2.filegroups <span class="token operator">=</span> f1
a1.sources.r2.filegroups.f1 <span class="token operator">=</span> /data_log/.*producerecord.csv
<span class="token comment"># r3</span>
a1.sources.r3.type <span class="token operator">=</span> TAILDIR
a1.sources.r3.positionFile <span class="token operator">=</span>/opt/module/flume-1.9.0/environmentdata/taildir_position.json
a1.sources.r3.filegroups <span class="token operator">=</span> f1
a1.sources.r3.filegroups.f1 <span class="token operator">=</span> /data_log/.*environmentdata.csv

<span class="token comment"># 定义sinks k1</span>
a1.sinks.k1.type <span class="token operator">=</span> org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.topic <span class="token operator">=</span> ChangeRecord
a1.sinks.k1.kafka.bootstrap.servers <span class="token operator">=</span> bigdata1:9092,bigdata2:9092,bigdata3:9092
a1.sinks.k1.kafka.flumeBatchSize <span class="token operator">=</span> <span class="token number">20</span>
a1.sinks.k1.kafka.producer.acks <span class="token operator">=</span> <span class="token number">1</span>
a1.sinks.k1.kafka.producer.linger.ms <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment"># k2</span>
a1.sinks.k2.type <span class="token operator">=</span> org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k2.kafka.topic <span class="token operator">=</span> ProduceRecord
a1.sinks.k2.kafka.bootstrap.servers <span class="token operator">=</span> bigdata1:9092,bigdata2:9092,bigdata3:9092
a1.sinks.k2.kafka.flumeBatchSize <span class="token operator">=</span> <span class="token number">20</span>
a1.sinks.k2.kafka.producer.acks <span class="token operator">=</span> <span class="token number">1</span>
a1.sinks.k2.kafka.producer.linger.ms <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment"># k3</span>
a1.sinks.k3.type <span class="token operator">=</span> org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k3.kafka.topic <span class="token operator">=</span> EnvironmentData
a1.sinks.k3.kafka.bootstrap.servers <span class="token operator">=</span> bigdata1:9092,bigdata2:9092,bigdata3:9092
a1.sinks.k3.kafka.flumeBatchSize <span class="token operator">=</span> <span class="token number">20</span>
a1.sinks.k3.kafka.producer.acks <span class="token operator">=</span> <span class="token number">1</span>
a1.sinks.k3.kafka.producer.linger.ms <span class="token operator">=</span> <span class="token number">1</span>

<span class="token comment"># 定义channel c1</span>
a1.channels.c1.type <span class="token operator">=</span> memory
a1.channels.c1.capacity <span class="token operator">=</span> <span class="token number">10000</span>
a1.channels.c1.transactionCapacity <span class="token operator">=</span> <span class="token number">10000</span>
<span class="token comment"># c2</span>
a1.channels.c2.type <span class="token operator">=</span> memory
a1.channels.c2.capacity <span class="token operator">=</span> <span class="token number">10000</span>
a1.channels.c2.transactionCapacity <span class="token operator">=</span> <span class="token number">10000</span>
<span class="token comment"># c3</span>
a1.channels.c3.type <span class="token operator">=</span> memory
a1.channels.c3.capacity <span class="token operator">=</span> <span class="token number">10000</span>
a1.channels.c3.transactionCapacity <span class="token operator">=</span> <span class="token number">10000</span>

<span class="token comment"># 描述和配置source  channel   sink之间的连接关系</span>
a1.sources.r1.channels <span class="token operator">=</span> c1
a1.sinks.k1.channel <span class="token operator">=</span> c1

a1.sources.r2.channels <span class="token operator">=</span> c2
a1.sinks.k2.channel <span class="token operator">=</span> c2

a1.sources.r3.channels <span class="token operator">=</span> c3
a1.sinks.k3.channel <span class="token operator">=</span> c3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>新增参数：</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402281021504.png" alt="image-20240228102128393"></p><p>运行flume脚本：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">flume-ng agent <span class="token parameter variable">-n</span> a1 <span class="token parameter variable">-c</span> <span class="token variable">$FLUME_HOME</span>/conf <span class="token parameter variable">-f</span> <span class="token variable">$FLUME_HOME</span>/job/industry.conf <span class="token parameter variable">-Dflume.root.logger</span><span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>运行结果如下:</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402292028076.png" alt="image-20240229202836977"></p><h6 id="3-4-2-2-任务二："><a href="#3-4-2-2-任务二：" class="headerlink" title="3.4.2.2 任务二："></a>3.4.2.2 任务二：</h6><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">2、编写新的Flume配置文件，将数据备份到HDFS目录<span class="token operator">/</span>user/test/flumebackup下，要求所有主题的数据使用同一个Flume配置文件完成，将Flume的配置截图粘贴至客户端桌面【Release\任务D提交结果<span class="token punctuation">.</span>docx】中对应的任务序号下。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>flume配置内容</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 定义这个agent中各组件的名字</span>
a2.sources <span class="token operator">=</span> r1
a2.sinks <span class="token operator">=</span> k1
a2.channels <span class="token operator">=</span> c1

<span class="token comment"># Describe/configure the source</span>
a2.sources.r1.type <span class="token operator">=</span> TAILDIR
a2.sources.r1.positionFile <span class="token operator">=</span> /opt/module/flume-1.9.0/tail_dir.json
a2.sources.r1.filegroups <span class="token operator">=</span> f1 f2 f3
<span class="token comment">#f1</span>
a2.sources.r1.filegroups.f1 <span class="token operator">=</span> /data_log/.*producerecord.csv
a2.sources.r1.headers.f1.headerKey1 <span class="token operator">=</span> producerecord
<span class="token comment">#f2</span>
a2.sources.r1.filegroups.f2 <span class="token operator">=</span> /data_log/.*changerecord.csv
a2.sources.r1.headers.f2.headerKey1 <span class="token operator">=</span> changerecord
<span class="token comment">#f3</span>
a2.sources.r1.filegroups.f3 <span class="token operator">=</span> /data_log/.*environmentdata.csv
a2.sources.r1.headers.f3.headerKey1 <span class="token operator">=</span> environmentdata
a2.sources.r1.fileHeader <span class="token operator">=</span> <span class="token boolean">true</span>

<span class="token comment"># Describe the sink</span>
a2.sinks.k1.type <span class="token operator">=</span> hdfs
a2.sinks.k1.hdfs.path <span class="token operator">=</span> hdfs:///user/test/flumebackup/%Y%m%d/%H/%<span class="token punctuation">&#123;</span>headerKey1<span class="token punctuation">&#125;</span>
<span class="token comment">#上传文件的前缀</span>
a2.sinks.k1.hdfs.filePrefix <span class="token operator">=</span> upload-
<span class="token comment">#是否按照时间滚动文件夹</span>
a2.sinks.k1.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment">#多少时间单位创建一个新的文件夹</span>
a2.sinks.k1.hdfs.roundValue <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment">#重新定义时间单位</span>
a2.sinks.k1.hdfs.roundUnit <span class="token operator">=</span> hour
<span class="token comment">#是否使用本地时间戳</span>
a2.sinks.k1.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment">#积攒多少个Event才flush到HDFS一次</span>
a2.sinks.k1.hdfs.batchSize <span class="token operator">=</span> <span class="token number">100</span>
<span class="token comment">#设置文件类型，可支持压缩</span>
a2.sinks.k1.hdfs.fileType <span class="token operator">=</span> DataStream
<span class="token comment">#多久生成一个新的文件</span>
a2.sinks.k1.hdfs.rollInterval <span class="token operator">=</span> <span class="token number">60</span>
<span class="token comment">#设置每个文件的滚动大小大概是128M</span>
a2.sinks.k1.hdfs.rollSize <span class="token operator">=</span> <span class="token number">134217700</span>
<span class="token comment">#文件的滚动与Event数量无关</span>
a2.sinks.k1.hdfs.rollCount <span class="token operator">=</span> <span class="token number">0</span>

<span class="token comment"># Use a channel which buffers events in memory</span>
a2.channels.c1.type <span class="token operator">=</span> memory
a2.channels.c1.capacity <span class="token operator">=</span> <span class="token number">10000</span>
a2.channels.c1.transactionCapacity <span class="token operator">=</span> <span class="token number">10000</span>

<span class="token comment"># Bind the source and sink to the channel</span>
a2.sources.r1.channels <span class="token operator">=</span> c1
a2.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>运行</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">flume-ng agent <span class="token parameter variable">-n</span> a2 <span class="token parameter variable">-c</span> <span class="token variable">$FLUME_HOME</span>/conf <span class="token parameter variable">-f</span> <span class="token variable">$FLUME_HOME</span>/jobs/hdfs.conf <span class="token parameter variable">-Dflume.root.logger</span><span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果如下：</p><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402292106764.png" alt="image-20240229210617647"></p><blockquote><p>发现数据已经在备份，到hdfs查看如下：</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402292107085.png" alt="image-20240229210721984"></p><blockquote><p>查看数据详情：</p></blockquote><p><img src="https://hj-typora-images-1319512400.cos.ap-guangzhou.myqcloud.com/images202402292108479.png" alt="image-20240229210800386"></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hdfs dfs <span class="token parameter variable">-cat</span> /user/test/flumebackup/20240723/15/changerecord/upload-.1721718299144 <span class="token operator">|</span> <span class="token function">head</span> <span class="token parameter variable">-n2</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>完成</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">無以菱</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://www.wylblog.cn/2024/11/27/flume-pei-zhi-1-9-0/">https://www.wylblog.cn/2024/11/27/flume-pei-zhi-1-9-0/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">無以菱</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/Bigdata/"><span class="chip bg-color">Bigdata</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,qzone,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/libs/share/js/social-share.min.js"></script></div></div></div><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fas fa-times"></i></a><h4 class="reward-title">你的赏识是我前进的动力</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias/wylblog/alipay.webp" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias/wylblog/wechat.webp" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script></div></div><style>.valine-card{margin:1.5rem auto}.valine-card .card-content{padding:20px 20px 5px 20px}#vcomments textarea{box-sizing:border-box;background:url(/medias/comment_bg.png) 100% 100% no-repeat}#vcomments p{margin:2px 2px 10px;font-size:1.05rem;line-height:1.78rem}#vcomments blockquote p{text-indent:.2rem}#vcomments a{padding:0 2px;color:#4cbf30;font-weight:500;text-decoration:none}#vcomments img{max-width:100%;height:auto;cursor:pointer}#vcomments ol li{list-style-type:decimal}#vcomments ol,ul{display:block;padding-left:2em;word-spacing:.05rem}#vcomments ul li,ol li{display:list-item;line-height:1.8rem;font-size:1rem}#vcomments ul li{list-style-type:disc}#vcomments ul ul li{list-style-type:circle}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}#vcomments table,td,th{border:0}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments h1{font-size:1.85rem;font-weight:700;line-height:2.2rem}#vcomments h2{font-size:1.65rem;font-weight:700;line-height:1.9rem}#vcomments h3{font-size:1.45rem;font-weight:700;line-height:1.7rem}#vcomments h4{font-size:1.25rem;font-weight:700;line-height:1.5rem}#vcomments h5{font-size:1.1rem;font-weight:700;line-height:1.4rem}#vcomments h6{font-size:1rem;line-height:1.3rem}#vcomments p{font-size:1rem;line-height:1.5rem}#vcomments hr{margin:12px 0;border:0;border-top:1px solid #ccc}#vcomments blockquote{margin:15px 0;border-left:5px solid #42b983;padding:1rem .8rem .3rem .8rem;color:#666;background-color:rgba(66,185,131,.1)}#vcomments pre{font-family:monospace,monospace;padding:1.2em;margin:.5em 0;background:#272822;overflow:auto;border-radius:.3em;tab-size:4}#vcomments code{font-family:monospace,monospace;padding:1px 3px;font-size:.92rem;color:#e96900;background-color:#f8f8f8;border-radius:2px}#vcomments pre code{font-family:monospace,monospace;padding:0;color:#e8eaf6;background-color:#272822}#vcomments pre[class*=language-]{padding:1.2em;margin:.5em 0}#vcomments code[class*=language-],pre[class*=language-]{color:#e8eaf6}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}#vcomments b,strong{font-weight:700}#vcomments dfn{font-style:italic}#vcomments small{font-size:85%}#vcomments cite{font-style:normal}#vcomments mark{background-color:#fcf8e3;padding:.2em}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}</style><div class="card valine-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="vcomments" class="card-content" style="display:grid"></div></div><script src="/libs/valine/av-min.js"></script><script src="/libs/valine/Valine.min.js"></script><script>new Valine({el:"#vcomments",appId:"Mte7fae2id8Jx9bKn48B0kdJ-gzGzoHsz",appKey:"RW87hMrhzc4zeYx3QkqSsIGr",serverURLs:"https://Mte7fae2.lc-cn-n1-shared.com",notify:!1,verify:!1,visitor:!0,avatar:"hide",pageSize:"10",lang:"zh-cn",placeholder:"留言请走心，不然小菱会生气哦~,Your thoughts, your stage 🎤"})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="far fa-dot-circle"></i>&nbsp;本篇</div><div class="card"><a href="/2024/11/27/flume-pei-zhi-1-9-0/"><div class="card-image"><img src="/medias/featureimages/12.webp" class="responsive-img" alt="Flume配置(1.9.0)和基本使用"> <span class="card-title">Flume配置(1.9.0)和基本使用</span></div></a><div class="card-content article-content"><div class="summary block-with-text"></div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-11-27 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BF%90%E7%BB%B4%E7%B3%BB%E5%88%97/" class="post-category">大数据运维系列</a></span></div></div><div class="card-action article-tags"><a href="/tags/Bigdata/"><span class="chip bg-color">Bigdata</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/2024/11/27/maxwell-pei-zhi/"><div class="card-image"><img src="/medias/featureimages/12.webp" class="responsive-img" alt="Maxwell配置和基本使用"> <span class="card-title">Maxwell配置和基本使用</span></div></a><div class="card-content article-content"><div class="summary block-with-text"></div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-11-27 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BF%90%E7%BB%B4%E7%B3%BB%E5%88%97/" class="post-category">大数据运维系列</a></span></div></div><div class="card-action article-tags"><a href="/tags/Bigdata/"><span class="chip bg-color">Bigdata</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0===window.getSelection||(""+(n=window.getSelection())).length<Number.parseInt("200")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"!==n.getRangeAt(0).commonAncestorContainer.nodeName&&"CODE"!==n.getRangeAt(0).commonAncestorContainer.nodeName||(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: WuYiling&#39; Blog<br />文章作者: 無以菱<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200))})</script><script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/libs/prism/prism.min.js"></script><script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=parseInt(.4*$(window).height()-64),e=$(".toc-widget"),n=($(window).scroll(function(){$(window).scrollTop()>t?e.addClass("toc-fixed"):e.removeClass("toc-fixed")}),"expanded"),i=$("#toc-aside"),l=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){i.hasClass(n)?(i.removeClass(n).hide(),l.removeClass("l9")):(i.addClass(n).show(),l.addClass("l9"));var e="artDetail",o="prenext-posts";if(0!==(e=$("#"+e)).length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#"+o).width(t)}})})</script></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2024</span> <a href="/about" target="_blank">無以菱</a> |&nbsp;每天进步一点点&nbsp;<a href="/about" target="_blank">(=ＴェＴ=)挨骂</a> |&nbsp;永远支持&nbsp;<a href="https://m.weibo.cn/u/3179885602" target="_blank">ZCY</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">65.5k</span> <span id="busuanzi_container_site_pv">&nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp; <span id="busuanzi_value_site_pv" class="white-color"></span> </span><span id="busuanzi_container_site_uv">&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp; <span id="busuanzi_value_site_uv" class="white-color"></span></span><br><span id="sitetime">Loading...</span><script>var seconds=1e3,minutes=60*seconds,hours=60*minutes,days=24*hours,calcSiteTime=function(){function e(){var e=new Date-a,s=Math.floor(e/days),n=Math.floor(e%days/hours),t=Math.floor(e%hours/minutes),e=Math.floor(e%minutes/seconds),o=`This site has been running for ${s} days ${n} hours ${t} minutes ${e} seconds.`,o=`<i class="fa-solid fa-rocket"></i>本站居然已经运行 ${s} 天 ${n} 小时 ${t} 分 ${e} 秒，如果出问题，那肯定是缓存的锅！`;document.getElementById("sitetime").innerHTML=o}var a=new Date("2024",9,"13","0","0","0");e(),setInterval(e,1e3)};calcSiteTime()</script><br></div><div class="col s12 m4 l4 social-link social-statis"></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script type="text/javascript">$(function(){var e,r,s;e="/search.xml",r="searchInput",s="searchResult",$.ajax({url:e,dataType:"xml",success:function(e){var t=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),e=document.getElementById(r),n=document.getElementById(s);e.addEventListener("input",function(){var o='<ul class="search-result-list">',h=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length<=0||(t.forEach(function(e){var n,t,r,s=!0,a=e.title.trim().toLowerCase(),l=e.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),i=0===(i=e.url).indexOf("/")?e.url:"/"+i,c=-1,u=-1;""!==a&&""!==l&&h.forEach(function(e,t){n=a.indexOf(e),c=l.indexOf(e),n<0&&c<0?s=!1:(c<0&&(c=0),0===t&&(u=c))}),s&&(o+="<li><a href='"+i+"' class='search-result-title'>"+a+"</a>",i=e.content.trim().replace(/<[^>]+>/g,""),0<=u&&(e=u+80,(e=0===(t=(t=u-20)<0?0:t)?100:e)>i.length&&(e=i.length),r=i.substr(t,e),h.forEach(function(e){var t=new RegExp(e,"gi");r=r.replace(t,'<em class="search-keyword">'+e+"</em>")}),o+='<p class="search-result">'+r+"...</p>"),o+="</li>")}),o+="</ul>",n.innerHTML=o)})}})})</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout(function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout(function(){$(".Cuteen_DarkSky").fadeOut(1e3,function(){$(this).remove()})},2e3)})}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script src="https://ssl.captcha.qq.com/TCaptcha.js"></script><script src="/libs/others/TencentCaptcha.js"></script><button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button><script>(()=>{var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)})()</script><script src="/libs/others/clicklove.js" async></script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" color="0,0,255" pointcolor="0,0,255" opacity="0.7" zindex="-1" count="99" src="/libs/background/canvas-nest.js"></script><script src="/libs/instantpage/instantpage.js" type="module"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"><script src="https://cdn.jsdelivr.net/gh/17lai/live2d-widget@latest/autoload.js"></script></body></html>